一般会把多台机器组成一个集群对外提供服务。然而，我们的网站对外提供的访问入口都是一个，比如 www.taobao.com。

那么当用户在浏览器输入 www.taobao.com 的时候如何将用户的请求分发到集群中不同的机器上呢，这就是负载均衡在做的事情。

>负载均衡设备的任务就是作为 Web 服务器流量的入口，挑选最合适的一台 Web 服务器，将客户端的请求转发给它处理，实现客户端到真实服务端的透明转发。


软件负载解决的两个核心问题是：**选谁**、**转发**，其中最著名的是 LVS(Linux Virtual Server)。
![image](http://p3.pstatp.com/large/pgc-image/152593234644360131a6d50)

# 负载均衡分类

负载均衡就是一种计算机网络技术，用来在多个计算机(计算机集群)、网络连接、CPU、磁碟驱动器或其他资源中分配负载，以达到最佳化资源使用、最大化吞吐率、最小化响应时间、同时避免过载的目的。

那么，这种计算机技术的实现方式有多种。大致可以分为以下几种，其中最常用的是四层和七层负载均衡。

##### 二层负载均衡

负载均衡服务器对外依然提供一个 VIP(虚IP)，集群中不同的机器采用相同 IP 地址，但机器的 MAC 地址不一样。当负载均衡服务器接受到请求之后，通过改写报文的目标 MAC 地址的方式将请求转发到目标机器实现负载均衡。

##### 三层负载均衡

三层负载均衡和二层负载均衡类似，负载均衡服务器对外依然提供一个VIP(虚IP)，但集群中不同的机器采用不同的 IP 地址。当负载均衡服务器接受到请求之后，根据不同的负载均衡算法，通过 IP 将请求转发至不同的真实服务器。

##### 四层负载均衡

四层负载均衡工作在 OSI 模型的传输层，由于在传输层，只有 TCP/UDP 协议，这两种协议中除了包含源 IP、目标 IP 以外，还包含源端口号及目的端口号。四层负载均衡服务器在接受到客户端请求后，之后通过修改数据包的地址信息(IP+端口号)将流量转发到应用服务器。

##### 七层负载均衡

七层负载均衡工作在 OSI 模型的应用层，应用层协议较多，常用 http、radius、DNS 等。七层负载就可以基于这些协议来负载。这些应用层协议中会包含很多有意义的内容。

# 常见负载均衡算法

上面介绍负载均衡技术的时候提到过，负载均衡服务器在决定将请求转发到具体哪台真实服务器时，是通过负载均衡算法来实现的。

负载均衡算法可以分为两类：

- 静态负载均衡算法，包括轮询、比率、优先权。
- 动态负载均衡算法，包括最少连接数、最快响应速度、观察方法、预测法、动态性能分配、动态服务器补充、服务质量、服务类型、规则模式。

### 轮询(Round Robin)
顺序循环将请求一次顺序循环地连接每个服务器。当其中某个服务器发生第二到第七层的故障，BIG-IP 就把它从顺序循环队列中拿出，不参加下一次的轮询，直到其恢复正常。

以轮询的方式依次请求调度不同的服务器;实现时，一般为服务器带上权重，这样有两个好处：
1. 针对服务器的性能差异可分配不同的负载。
2. 当需要将某个结点剔除时，只需要将其权重设置为 0 即可。

- 优点：实现简单、高效;易水平扩展。
- 缺点：请求到目的结点的不确定，造成其无法适用于有写的场景(缓存，数据库写)。


- 应用场景：数据库或应用服务层中只有读的场景。

### 随机方式
请求随机分布到各个结点;在数据足够大的场景能达到一个均衡分布。

- 优点：实现简单、易水平扩展。
- 缺点：同 Round Robin，无法用于有写的场景。


- 应用场景：数据库负载均衡，也是只有读的场景。

### 哈希方式
根据 key 来计算需要落在的结点上，可以保证一个同一个键一定落在相同的服务器上。

- 优点：相同 key 一定落在同一个结点上，这样就可用于有写有读的缓存场景。
- 缺点：在某个节点故障后，会导致哈希键重新分布，造成命中率大幅度下降。

>解决：一致性哈希 or 使用 keepalived 保证任何一个节点的高可用性，故障后会有其他节点顶上来。

- 应用场景：缓存，有读有写。

### 一致性哈希
在服务器一个节点出现故障时，受影响的只有这个节点上的 key，最大程度的保证命中率。

>例如 twemproxy 中的 ketama 方案;生产实现中还可以规划指定子 key 哈希，从而保证局部相似特征的键能分布在同一个服务器上。

- 优点：节点故障后命中率下降有限。
- 应用场景：缓存。

### 根据键的范围来负载
根据键的范围来负载，前 1 亿个键都存放到第一个服务器，1~2 亿在第二个服务器。

- 优点：水平扩展容易，存储不够用时，加服务器存放后续新增数据。
- 缺点：负载不均;数据库的分布不均衡。(数据有冷热区分，一般最近注册的用户更加活跃，这样造成后续的服务器非常繁忙，而前期的节点空闲很多)

- 适用场景：数据库分片负载均衡。

### 根据键对服务器节点数取模来负载
根据键对服务器节点数取模来负载;比如有 4 台服务器，key 取模为 0 的落在第一个节点，1 落在第二个节点上。

- 优点：数据冷热分布均衡，数据库结点负载均衡分布。
- 缺点：水平扩展较难。


- 适用场景：数据库分片负载均衡。

### 纯动态结点负载均衡
根据 CPU、IO、网络的处理能力来决策接下来的请求如何调度。

- 优点：充分利用服务器的资源，保证多个结点上负载处理均衡。
- 缺点：实现起来复杂，真实使用较少。

### 不用主动负载均衡
使用消息队列转为异步模型，将负载均衡的问题消灭;负载均衡是一种推模型，一直向你发数据。

那么将所有的用户请求发到消息队列中，所有的下游节点谁空闲，谁上来取数据处理;转为拉模型之后，消除了对下行节点负载的问题。

- 优点：通过消息队列的缓冲，保护后端系统，请求剧增时不会冲垮后端服务器;水平扩展容易，加入新结点后，直接取 queue 即可。
- 缺点：不具有实时性。


- 应用场景：不需要实时返回的场景。比如，12036 下订单后，立刻返回提示信息：您的订单进去排队了...等处理完毕后，再异步通知。

### 比率(Ratio)
给每个服务器分配一个加权值为比例，根椐这个比例，把用户的请求分配到每个服务器。

当其中某个服务器发生第 2 到第 7 层的故障，BIG-IP 就把其从服务器队列中拿出，不参加下一次的用户请求的分配，直到其恢复正常。

### 优先权(Priority)
给所有服务器分组，给每个组定义优先权，BIG-IP 用户的请求，分配给优先级最高的服务器组(在同一组内，采用轮询或比率算法，分配用户的请求)。

当最高优先级中所有服务器出现故障，BIG-IP 才将请求送给次优先级的服务器组。这种方式，实际为用户提供一种热备份的方式。

### 最少的连接方式(Least Connection)
传递新的连接给那些进行最少连接处理的服务器。

当其中某个服务器发生第二到第七层的故障，BIG-IP 就把它从服务器队列中拿出，不参加下一次的用户请求的分配，直到其恢复正常。

### 最快模式(Fastest)
传递连接给那些响应最快的服务器。当其中某个服务器发生第二到第七层的故障，BIG-IP 就把它从服务器队列中拿出，不参加下一次的用户请求的分配，直到其恢复正常。

### 观察模式(Observed)
连接数目和响应时间以这两项的最佳平衡为依据为新的请求选择服务器。

当其中某个服务器发生第二到第七层的故障，BIG-IP 就把它从服务器队列中拿出，不参加下一次的用户请求的分配，直到其恢复正常。

### 预测模式(Predictive)
BIG-IP 利用收集到的服务器当前的性能指标，进行预测分析，选择一台服务器在下一个时间片内，其性能将达到最佳的服务器相应用户的请求(被 BIG-IP 进行检测)。

### 动态性能分配(Dynamic Ratio-APM)
根据 BIG-IP 收集到的应用程序和应用服务器的各项性能参数，动态调整流量分配。

### 动态服务器补充(Dynamic Server Act)
当主服务器群中因故障导致数量减少时，动态地将备份服务器补充至主服务器群。

### 服务质量(QoS)
按不同的优先级对数据流进行分配。

### 服务类型(ToS)
按不同的服务类型(在 Type of Field 中标识)负载均衡对数据流进行分配。

### 规则模式
针对不同的数据流设置导向规则，用户可自行调整。