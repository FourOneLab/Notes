机器学习技术在当代社会已经发挥了很大的作用：从**网络搜索**到社交网络中的**内容过滤**到电子商务网站的**个性化推荐**，它正在快速的出现在用户的消费品中，如摄像机和智能手机。机器学习系统可以用来识别图像中的物体，将语音转变成文字，匹配用户感兴趣的新闻、消息和产品等，也可以选择相关的搜索结果。

深度学习（Deep Learning）（也称为深度结构学习【Deep Structured Learning】、层次学习【Hierarchical Learning】或者是深度机器学习【Deep Machine Learning】）是一类算法集合，是机器学习的一个分支。它尝试为数据的高层次摘要进行建模。

> 以一个简单的例子来说，假设有两组神经元，一个是接受输入的信号，一个是发送输出的信号。当输入层接收到输入信号的时候，它将输入层做一个简单的修改并传递给下一层。在一个深度网络中，输入层与输出层之间可以有很多的层（这些层并不是由神经元组成的，但是它可以以神经元的方式理解），允许算法使用多个处理层，并可以对这些层的结果进行线性和非线性的转换。


近些年来，深度学习通过在某些任务中极佳的表现正在改革机器学习。深度学习方法在**会话识别**、**图像识别**、**对象侦测**以及如**药物发现**和**基因组学**等领域表现出了惊人的准确性。

> “深度学习”这个词语很古老，它在1986年由Dechter在机器学习领域提出，然后在2000年由Aizenberg等人引入到人工神经网络中。而现在，由于Alex Krizhevsky在2012年使用卷积网络结构赢得了ImageNet比赛之后受到大家的瞩目。

## 深度学习架构
- 生成式深度结构（Generative deep architectures），主要是用来描述具有高阶相关性的可观测数据或者是可见的对象的特征，主要用于模式分析或者是总和的目的，或者是描述这些数据与他们的类别之间的联合分布。（其实就是类似与生成模型）**【深度前馈网络，Deep feed-forward networks】**

- 判别式深度结构（Discriminative deep architectures），主要用于提供模式分类的判别能力，经常用来描述在可见数据条件下物体的后验类别的概率。（类似于判别模型）**【卷积网络，Convolution networks】**

- 混合深度结构（Hybrid deep architectures），目标是分类，但是和生成结构混合在一起了。比如以正在或者优化的方式引入生成模型的结果，或者使用判别标注来学习生成模型的参数。**【递归神经网络，Recurrent Networks】**


## 深度前馈网络 Deep feed-forward networks
深度前馈网络也叫做前馈神经网络，或者是多层感知机（MultilayerPerceptrons，MLPs），是深度学习模型中的精粹。

前馈网络的目标是近似某些函数。例如，对于一个分类器，y=f(x)来说，它将一个输入值x变成对应的类别y。前馈网络就是定义一个映射y=f(x;θ)，并学习出参数θ使得产生最好的函数近似。

简而言之，神经网络可以定义成输入层，隐含层和输出层。其中，输入层接受数据，隐含层处理数据，输出层则输出最终结果。这个信息流就是接受x，通过处理函数f，在达到输出y。这个模型并没有任何的反馈连接，因此被称为前馈网络。


## 卷积神经网络 Convolution Neural Networks
在机器学习中，卷积神经网络（简称CNN或者ConvNet）是一种前馈神经网络，它的神经元的连接是启发于动物视觉皮层。单个皮质神经元可以对某个有限空间区域的刺激作出反应。这个有限空间可以称为接受域。不同的神经元的接受域可以重叠，从组成了所有的可见区域。那么，一个神经元对某个接受域内的刺激作出反应，在数学上可以使用卷积操作来近似。也就是说，卷积神经网络是受到生物处理的启发，设计使用最少的预处理的多层感知机的变体。

卷积神经网络在图像和视频识别、推荐系统以及自然语言处理中都有广泛的运用。

卷积神经网络主要包含四块：

- 卷积层（Convolutional Layer）
- 激活函数（Activation Function）
- 池化层（Pooling Layer）
- 全连接层（Fully Connected Layer）

### 卷积层 Convolutional Layer

卷积层是基于单词“卷积（Convolution）”而来，这是一种数学上的操作，它是对两个变量f\*g进行操作产生第三个变量。它和互相关（cross-correlation）很像。卷积层的输入是一个m×m×r图像，其中m是图像的高度和宽度，r是通道的数量，例如，一个RGB图像的通道是3，即r=3。卷积层有k个滤波器【filters】（或者称之为核【kernel】），其大小是n×n×q，这里的n是比图像维度小的一个数值，q既可以等于通道数量，也可以小于通道数量，具体根据不同的滤波器来定。

### 激活函数 Activation Function

为了实现复杂的映射函数，我们需要使用激活函数。它可以带来非线性的结果，而非线性可以使得我们很好的拟合各种函数。同时，激活函数对于压缩来自神经元的无界线性加权和也是重要的。

激活函数很重要，它可以避免我们把大的数值在高层次处理中进行累加。激活函数有很多，常用的有sigmoid，tanh和ReLU。

### 池化层 Pooling Layer

池化是一个基于样本的离散化过程。其目的上降低输入表示的采样（这里的输入可以是图像，隐层的输出等），减少它们的维度，并允许我们假设特征已经被包含在了子区域中。

这部分的作用是通过提供一种抽象的形式表示来帮助过拟合表示。同样的，它也通过减少了参数的数量降低了计算的复杂度并为内部的表示提供一个基本的不变性的转换。

目前最常用的池化技术有Max-Pooling、Min-Pooling和Average-Pooling。

### 全连接层 Fully Connected Layer

“全连接”的意思是指先前的层里面的所有的神经元都与后一个层里面的所有的神经元相连。全连接层是一种传统的多层感知机，在输出层，它使用softmax激活函数或者其他激活函数。


## 递归神经网络 Recurrent Neural Networks

在传统的神经网络中，我们假设所有的输入之间相互独立。但是对于很多任务来说，这并不是一个好的主意。如果你想知道一个句子中下一个单词是什么，你最好知道之前的单词是什么。RNN之所以叫RNN就是它对一个序列中所有的元素都执行相同的任务，所有的输出都依赖于先前的计算。另一种思考RNN的方式是它会记住所有之前的计算的信息。

一个RNN里面有很多循环，它可以携带从输入中带来的信息。如下图所示，x_t是一种输入，A是RNN里面的一部分，h_t是输出。本质上，您可以从句子中输入文字，甚至还可以从字符串中输入x_t格式的字符，通过RNN可以提供一个h_t。 RNN的一些类型是LSTM，双向RNN，GRU等。


```
graph LR
x_t-->A
A-->h_t
```


由于任何输入和输出都可以在RNN中变成一对一或者多对多的形式，RNN可以用在自然语言处理、机器翻译、语言模型、图像识别、视频分析、图像生成、验证码识别等领域。


## 机器学习和深度学习的对比
### 数据依赖性

深度学习与传统的机器学习最主要的区别在于随着数据规模的增加其性能也不断增长。当数据很少时，深度学习算法的性能并不好。这是因为深度学习算法需要大量的数据来完美地理解它。另一方面，在这种情况下，传统的机器学习算法使用制定的规则，性能会比较好。下图总结了这一事实。

### 硬件依赖

深度学习算法需要进行大量的矩阵运算，GPU 主要用来高效优化矩阵运算，所以 GPU 是深度学习正常工作的必须硬件。与传统机器学习算法相比，深度学习更依赖安装 GPU 的高端机器。

### 特征处理

特征处理是将领域知识放入特征提取器里面来减少数据的复杂度并生成使学习算法工作的更好的模式的过程。特征处理过程很耗时而且需要专业知识。

在机器学习中，大多数应用的特征都需要专家确定然后编码为一种数据类型。

特征可以是像素值、形状、纹理、位置和方向。大多数机器学习算法的性能依赖于所提取的特征的准确度。

深度学习尝试从数据中直接获取高等级的特征，这是深度学习与传统机器学习算法的主要的不同。基于此，深度学习削减了对每一个问题设计特征提取器的工作。例如，卷积神经网络尝试在前边的层学习低等级的特征(边界，线条)，然后学习部分人脸，然后是高级的人脸的描述。


### 问题解决方式

当应用传统机器学习算法解决问题的时候，传统机器学习通常会将问题分解为多个子问题并逐个子问题解决最后结合所有子问题的结果获得最终结果。相反，深度学习提倡直接的端到端的解决问题。

### 执行时间

通常情况下，训练一个深度学习算法需要很长的时间。这是因为深度学习算法中参数很多，因此训练算法需要消耗更长的时间。最先进的深度学习算法 ResNet完整地训练一次需要消耗两周的时间，而机器学习的训练会消耗的时间相对较少，只需要几秒钟到几小时的时间。

但两者测试的时间上是完全相反。深度学习算法在测试时只需要很少的时间去运行。如果跟 k-nearest neighbors（一种机器学习算法）相比较，测试时间会随着数据量的提升而增加。不过这不适用于所有的机器学习算法，因为有些机器学习算法的测试时间也很短。


### 可解释性

至关重要的一点，我们把可解释性作为比较机器学习和深度学习的一个因素。

我们看个例子。假设我们使用深度学习去自动为文章评分。深度学习可以达到接近人的标准，这是相当惊人的性能表现。但是这仍然有个问题。深度学习算法不会告诉你为什么它会给出这个分数。当然，在数学的角度上，你可以找出来哪一个深度神经网络节点被激活了。但是我们不知道神经元应该是什么模型，我们也不知道这些神经单元层要共同做什么。所以无法解释结果是如何产生的。

另一方面，为了解释为什么算法这样选择，像决策树(decision trees)这样机器学习算法给出了明确的规则，所以解释决策背后的推理是很容易的。因此，决策树和线性/逻辑回归这样的算法主要用于工业上的可解释性。