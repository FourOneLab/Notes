kubernetes项目的监控体系曾经非常繁杂，如今已经演变为以Prometheus项目为核心的一套统一的方案。

# Prometheus
与kubernetes一样，来自Google的Borg体系，原型系统是BorgMon，几乎不Borg同时诞生的内部监控系统。Prometheus与kubernetes一样，希望通过对用户友好的凡是，将Google内部系统的设计理念，传递给用户和开发者。

作为一个监控系统，Prometheus项目的作用和工作方式，如下图所示：

![image](https://static001.geekbang.org/resource/image/2a/d3/2ada1ece66fcc81d704c2ba46f9dd7d3.png)

Prometheus项目工作的核心，是使用Pull（抓取）的方式去搜集被监控对象的Metrics数据（监控指标数据），然后，再把这些数据保存在一个TSDB（时序数据库，如OpenTSDB、InfluxDB等）当中，以便后续 可以按照时间进行检索。有了这套核心的监控机制，剩下的组件就是用来配合这套机制运行的，如：
- Pushgateway，运行被监控对象以Push的方式向Prometheus推送Metrics数据
- Alertmanager，根据Metrics信息灵活地配置报警
- Grafana，对外暴露出可灵活配置的监控数据可视化界面

有了Prometheus之后，可以按照Metrics数据的来源，对kubernetes的监控体系做一个汇总：
1. 第一种Metrics，是宿主机的监控数据。这部分数据借助Prometheus的Node Exporter工具，它会议DaemonSet的方式运行在宿主机上。
> 所谓Exporter就是代替被监控对象来对Prometheus暴露出可以被抓取的Metrics信息的一个辅助进程。Node Exporter可以暴露给Prometheus采集的Metrics数据，也不单单是节点的负载（Load）、CPU、内存、磁盘以及网络等常规信息，还包括如下信息，参考这里https://github.com/prometheus/node_exporter#enabled-by-default。
2. 第二种Metrics，是来自于kubernetes的APIServer、kubelet、等组件的/metrics API。除了常规的CPU、内存的信息外，还包括各组件的核心监控指标（如APIServer在/metrics API中暴露出哥哥Controller的工作队列的长度，请求的QPS和延迟数据等），这些信息是检查kubernetes本身工作情况的主要依据。
3. 第三种Metrics，是kubernetes相关的监控数据（称为kubernetes核心监控数据core metrics）。包括Pod、Node、容器、Service等主要Kubernetes核心概念的Metrics。
> 其中容器相关的Metrics主要来自kubelet内置的cAdvisor服务（随着kubelet一起启动），它能够提供的信息可细化到每一个容器的CPU、文件系统、内存、网络等资源的使用。

**这里提到的kubernetes核心监控数据，使用的是kubernetes的一个重要的扩展能力，Metrics Servicer**。

> Metrics Server在kubernetes社区的定位，是用来取代Heapster项目，早起的时候使用Heapster获取kubernetes的监控数据（如Pod和Node的资源使用情况）的主要渠道。Metrics Server则把这些信息，通过标准kubernetes API暴露出来，这样Metrics信息就跟Heapster完全解耦了，Heapster就退出了。

有了Metrics Server，用户可以通过标准的kubernetes API来访问这些监控数据，如下面的URL：
```
http://127.0.0.1:8001/apis/metrics.k8s.io/v1beta1/namespaces/<namespace-name>/pods/<pod-name>

```
访问这个API时，就会返回一个Pod的监控数据，这些数据是从kubelet的Summary API（`<kubelet_ip>:<kubelet_port>/stats/summary`）采集而来。Summary API返回的信息，既包括cAdVisor的监控数据，也包括kubelet本身汇总的信息。

> Metrics Server并不是kube-apiserver的一部分，通过Aggregator插件机制，在独立部署的情况下同kube-apiserver一起统一对外服务。

# Aggregator
Aggregator APIServer的工作原理如下图所示：

![image](https://static001.geekbang.org/resource/image/0b/09/0b767b5224ad1906ddc4cce075618809.png)

当kubernetes的API Server开启Aggregator模式后，访问`apis/metrics.k8s.io/v1beta1`的时候，实际上访问的是kube-aggregator的代理，而kube-apiserver真是这个代理的一个后端，Metrics Server是另一个后端。

在这种机制下，可以添加更多的后端给这个kube-aggregator，**它其实是一个根据URL选择具体API的后端代理服务器**。通过这种方式可以很方便的扩展kubernetes的API。

## 开启Aggregator
1. 使用kubeadm或者kube-up.sh脚本部署kubernetes集群，Aggregator模式是默认开启的
2. 手动搭建，需要在kube-apiserver的启动参数中加上如下配置

```
--requestheader-client-ca-file=<path to aggregator CA cert>
--requestheader-allowed-names=front-proxy-client
--requestheader-extra-headers-prefix=X-Remote-Extra-
--requestheader-group-headers=X-Remote-Group
--requestheader-username-headers=X-Remote-User
--proxy-client-cert-file=<path to aggregator proxy cert>
--proxy-client-key-file=<path to aggregator proxy key>

```
这些配置的作用，主要是为Aggregator这一层设置对应的key和cert文件。这些文件的生成需要手动完成，具体流程参考这里：https://github.com/kubernetes-incubator/apiserver-builder-alpha/blob/master/docs/concepts/auth.md

Aggregator功能开启之后，只需要将Metrics Server的YAML文件部署起来，如下所示：
```bash
$ git clone https://github.com/kubernetes-incubator/metrics-server
$ cd metrics-server
$ kubectl create -f deploy/1.8+/

# metrics.k8s.io这个API会出现在kubernetes API列表中 
```
作为用户只需要将Prometheus Operator在kubernetes集群里部署起来，然后把Metrics源配置起来，让Prometheus自己进行采集即可。

在具体的监控指标规划上，可采用业界统一的USE原则和RED原则。

USE原则指的是，按照如下三个维度来规划资源监控指标：
1. 利用率（Utilization），资源被有效利用起来提供服务的平均时间占比
2. 饱和度（Saturation），资源拥挤的成都，比如工作队里的长度
3. 错误率（Errors），错误的数量

RED原则指的是，按照如下三个维度规划服务监控指标：
1. 每秒请求数量（Rate）
2. 每秒错误数量（Errors）
3. 服务响应时间（Duration）

USE原则主要关注**资源**，如某个节点和容器的资源使用情况，RED原则主要关注**服务**，如kube-apiserver或者某个应用的工作情况。

